# RostraCore Technical Architecture & Optimization Strategy
## Computer Science PhD √ó Data Science PhD Approach

---

## PHILOSOPHY: "PERFORMANCE IS A FEATURE"

Every millisecond matters. Users judge quality by speed. A slow product feels broken, even if it works perfectly.

**Target Performance Metrics:**
- **Landing page:** <1.5s First Contentful Paint (FCP)
- **Dashboard load:** <2s Time to Interactive (TTI)
- **Roster generation:** <10s for 200 shifts (already achieved ‚úì)
- **API response:** <100ms for 95% of requests
- **Uptime:** 99.95% (4.5 hours downtime/year max)

---

## PART 1: CURRENT ARCHITECTURE ASSESSMENT

### ‚úÖ **Strengths**

1. **Modern Tech Stack**
   - FastAPI (async-first, high performance)
   - Next.js 14 (React Server Components, built-in optimization)
   - PostgreSQL (robust, ACID-compliant)
   - TypeScript (type safety, maintainability)

2. **Sophisticated Algorithms**
   - Three optimization engines (CP-SAT, MILP, Hungarian)
   - Constraint satisfaction for compliance
   - Fairness metrics built-in

3. **Clean Separation**
   - Frontend/Backend decoupled (scalable independently)
   - API versioning (/api/v1/)
   - Database ORM abstraction (SQLAlchemy)

### ‚ö†Ô∏è **Critical Gaps**

1. **No Caching Layer**
   - Every dashboard request hits database
   - Repeated calculations (costs, fill rates, etc.)
   - **Impact:** Slow dashboard, high DB load

2. **No Monitoring/Observability**
   - No APM (Application Performance Monitoring)
   - No error tracking (Sentry, etc.)
   - No real-time metrics
   - **Impact:** Can't diagnose issues, slow to detect problems

3. **Synchronous Optimization**
   - Roster generation blocks API request
   - User waits 10-120 seconds with no feedback
   - **Impact:** Poor UX, timeout risks

4. **No CDN**
   - Static assets served from Next.js server
   - No geographic distribution
   - **Impact:** Slow load times, especially mobile

5. **Limited Scalability**
   - Single database instance
   - No load balancing
   - No horizontal scaling strategy
   - **Impact:** Can't handle growth beyond ~500 customers

6. **No Backup/DR Strategy Visible**
   - Unclear backup frequency
   - No disaster recovery plan
   - **Impact:** Business continuity risk

---

## PART 2: PROPOSED ARCHITECTURE (NEXT 12 MONTHS)

### Phase 1: Immediate Wins (Weeks 1-4)

#### üöÄ **A. Add Redis Caching Layer**

**Problem:** Dashboard makes 8 DB queries every load (even if data hasn't changed)

**Solution:** Cache expensive queries

```python
# Example: Cache dashboard metrics for 5 minutes
from redis import Redis
import json

cache = Redis(host='localhost', port=6379, db=0)

@app.get("/api/v1/dashboard/metrics")
async def get_dashboard_metrics(org_id: int):
    # Check cache first
    cache_key = f"dashboard:metrics:{org_id}"
    cached = cache.get(cache_key)

    if cached:
        return json.loads(cached)

    # If not cached, compute from DB
    metrics = compute_expensive_metrics(org_id)

    # Cache for 5 minutes (300 seconds)
    cache.setex(cache_key, 300, json.dumps(metrics))

    return metrics
```

**What to Cache:**
- Dashboard metrics (5 min TTL)
- Roster summaries (1 hour TTL)
- Employee lists (10 min TTL)
- Site lists (10 min TTL)
- Certification alerts (30 min TTL)

**Cache Invalidation:**
- On roster publish ‚Üí Clear roster caches
- On employee add/edit ‚Üí Clear employee caches
- On shift create ‚Üí Clear shift caches

**Expected Impact:**
- Dashboard load: 2s ‚Üí 0.3s (6-7x faster)
- Database load: -70%
- User experience: Instant feel

**Cost:** Redis Cloud (1GB): $7/month or self-hosted: $0

---

#### üìä **B. Add Performance Monitoring (APM)**

**Problem:** No visibility into what's slow, what's breaking

**Solution:** Implement Sentry + Custom Metrics

**Tools:**
1. **Sentry** (Error Tracking)
   - Captures all Python exceptions
   - Frontend errors (React crashes, API failures)
   - Performance profiling (which functions are slow?)
   - Free tier: 5K events/month

2. **Prometheus + Grafana** (Metrics)
   - System metrics (CPU, memory, disk)
   - Application metrics (request rates, latency)
   - Custom business metrics (rosters/day, active users)

**Implementation:**

```python
# backend/app/main.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration

sentry_sdk.init(
    dsn="https://your-sentry-dsn",
    integrations=[FastApiIntegration()],
    traces_sample_rate=0.1,  # 10% of requests profiled
    environment="production"
)

# Add custom context
from sentry_sdk import set_user, set_tag

@app.middleware("http")
async def add_sentry_context(request: Request, call_next):
    if request.state.user:
        set_user({"id": request.state.user.user_id, "email": request.state.user.email})
        set_tag("org_id", request.state.user.org_id)

    response = await call_next(request)
    return response
```

**Custom Metrics to Track:**

```python
from prometheus_client import Counter, Histogram, Gauge

# Business metrics
rosters_generated = Counter('rosters_generated_total', 'Total rosters generated', ['algorithm', 'status'])
optimization_duration = Histogram('optimization_duration_seconds', 'Roster optimization time')
active_users = Gauge('active_users_total', 'Currently active users')

# Usage:
rosters_generated.labels(algorithm='cpsat', status='optimal').inc()
optimization_duration.observe(duration_seconds)
```

**Expected Impact:**
- Detect errors in <5 minutes (vs. users reporting them)
- Identify slow endpoints immediately
- Proactive performance optimization

**Cost:** Sentry free tier + Prometheus/Grafana (self-hosted free)

---

#### ‚ö° **C. Async Job Queue for Long-Running Tasks**

**Problem:** Roster optimization (10-120s) blocks API request ‚Üí timeouts, poor UX

**Solution:** Move to background job queue with progress updates

**Architecture:**

```
User clicks "Generate Roster"
    ‚Üì
Frontend ‚Üí POST /api/v1/roster/generate
    ‚Üì
Backend creates job ‚Üí Returns job_id immediately (< 100ms)
    ‚Üì
Frontend polls GET /api/v1/roster/job/{job_id} every 2 seconds
    ‚Üì
Background worker (Celery) runs optimization
    ‚Üì
Updates job status: pending ‚Üí optimizing ‚Üí completed
    ‚Üì
Frontend shows progress bar + status updates
    ‚Üì
When completed ‚Üí Frontend fetches results
```

**Technology: Celery + Redis**

```python
# backend/app/celery_app.py
from celery import Celery

celery_app = Celery(
    'rostracore',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/0'
)

# backend/app/tasks/roster_tasks.py
from app.celery_app import celery_app
from app.optimization.cpsat_optimizer import CPSATOptimizer

@celery_app.task(bind=True)
def generate_roster_task(self, start_date, end_date, site_ids, algorithm='production'):
    """Background task for roster generation"""

    # Update progress (visible to frontend)
    self.update_state(state='OPTIMIZING', meta={'progress': 0, 'status': 'Analyzing constraints...'})

    optimizer = CPSATOptimizer()

    # Run optimization
    result = optimizer.optimize(start_date, end_date, site_ids)

    self.update_state(state='OPTIMIZING', meta={'progress': 80, 'status': 'Finalizing assignments...'})

    return result


# backend/app/routers/roster.py
@router.post("/generate")
async def generate_roster(request: RosterRequest):
    """Start roster generation (non-blocking)"""

    # Enqueue task
    task = generate_roster_task.delay(
        request.start_date,
        request.end_date,
        request.site_ids,
        request.algorithm
    )

    return {
        "job_id": task.id,
        "status": "pending",
        "message": "Roster generation started"
    }

@router.get("/job/{job_id}")
async def get_job_status(job_id: str):
    """Check job progress"""
    task = AsyncResult(job_id, app=celery_app)

    if task.state == 'PENDING':
        return {"status": "pending", "progress": 0}
    elif task.state == 'OPTIMIZING':
        return {"status": "optimizing", "progress": task.info.get('progress', 50), "message": task.info.get('status', '')}
    elif task.state == 'SUCCESS':
        return {"status": "completed", "progress": 100, "result": task.result}
    else:
        return {"status": "failed", "error": str(task.info)}
```

**Frontend Integration:**

```typescript
// frontend/services/api.ts
export const rosterApi = {
  async generateRoster(data: RosterRequest): Promise<{ job_id: string }> {
    const response = await api.post('/roster/generate', data);
    return response.data;
  },

  async pollJobStatus(jobId: string): Promise<JobStatus> {
    const response = await api.get(`/roster/job/${jobId}`);
    return response.data;
  }
};

// frontend/app/roster/page.tsx
const generateRoster = async () => {
  setLoading(true);

  // Start job
  const { job_id } = await rosterApi.generateRoster(formData);

  // Poll for progress
  const interval = setInterval(async () => {
    const status = await rosterApi.pollJobStatus(job_id);

    setProgress(status.progress);
    setStatusMessage(status.message);

    if (status.status === 'completed') {
      clearInterval(interval);
      setResult(status.result);
      setLoading(false);
    } else if (status.status === 'failed') {
      clearInterval(interval);
      setError(status.error);
      setLoading(false);
    }
  }, 2000); // Poll every 2 seconds
};
```

**Expected Impact:**
- No more API timeouts (job runs in background)
- Better UX (real-time progress updates)
- Scalable (can run multiple optimizations in parallel)

**Cost:** Celery workers (2 instances): $0 (same server) or $20/month (dedicated)

---

#### üåç **D. CDN for Static Assets**

**Problem:** All assets (CSS, JS, images) served from Next.js server ‚Üí slow for mobile users

**Solution:** Use CDN (Content Delivery Network)

**Options:**
1. **Vercel** (Next.js hosting): Built-in CDN, zero config
   - Cost: Free for starter, $20/month for pro
   - Pros: Seamless integration, automatic optimization
   - Cons: Vendor lock-in

2. **Cloudflare** (CDN proxy): Cache entire site
   - Cost: Free tier (up to 100K requests/day)
   - Pros: DDoS protection, analytics, flexible
   - Cons: Requires DNS changes

3. **AWS CloudFront**: S3 + CloudFront for assets
   - Cost: ~$10/month for small traffic
   - Pros: Full control, integrates with AWS ecosystem
   - Cons: More complex setup

**Recommendation:** Start with Cloudflare (free, easy setup)

**Implementation:**
1. Point domain to Cloudflare
2. Enable caching for static assets
3. Configure cache rules:
   - Images: Cache 1 month
   - CSS/JS: Cache 1 week (or cache-bust on deploy)
   - HTML: Cache 5 minutes (or no-cache for dynamic)

**Expected Impact:**
- Landing page load: 3s ‚Üí 1.2s (2.5x faster)
- Bandwidth costs: -60%
- Global reach (fast in Cape Town AND Johannesburg)

**Cost:** $0 (Cloudflare free tier)

---

### Phase 2: Scaling Foundation (Weeks 5-12)

#### üóÑÔ∏è **E. Database Optimization**

**Current Bottlenecks:**

1. **N+1 Queries:** Loading shifts with employees/sites requires multiple queries

```python
# ‚ùå Bad: N+1 queries (1 for shifts + N for employees)
shifts = db.query(Shift).all()
for shift in shifts:
    print(shift.employee.first_name)  # Separate query for EACH shift
```

**Solution: Eager loading**

```python
# ‚úÖ Good: Single query with JOIN
shifts = db.query(Shift).options(
    joinedload(Shift.employee),
    joinedload(Shift.site)
).all()
```

2. **Missing Indexes:** Some common queries not indexed

```sql
-- Add indexes for common query patterns
CREATE INDEX idx_shifts_date_site ON shifts(start_time, site_id);
CREATE INDEX idx_employees_status ON employees(status) WHERE status = 'active';
CREATE INDEX idx_certifications_expiry ON certifications(expiry_date) WHERE expiry_date > NOW();
CREATE INDEX idx_roster_status ON rosters(status, start_date);
```

3. **Heavy Aggregations:** Cost calculations done in Python (slow)

```python
# ‚ùå Bad: Load all shifts into memory, calculate in Python
shifts = db.query(Shift).all()
total_cost = sum([s.cost for s in shifts])
```

**Solution: Push to database**

```sql
-- ‚úÖ Good: Let PostgreSQL do the math (100x faster)
SELECT
    SUM(total_cost) as total_cost,
    SUM(overtime_hours) as total_overtime,
    COUNT(*) as shift_count
FROM shift_assignments
WHERE roster_id = :roster_id;
```

**Expected Impact:**
- Dashboard queries: 2s ‚Üí 0.3s (6-7x faster)
- Roster summary: 5s ‚Üí 0.5s (10x faster)
- Scalability: Can handle 10x more data

---

#### üì¶ **F. Database Partitioning (For Growth)**

**Problem:** As data grows (10K+ rosters, 100K+ shifts), queries slow down

**Solution: Time-based partitioning**

```sql
-- Partition shifts table by month
CREATE TABLE shifts (
    shift_id SERIAL PRIMARY KEY,
    start_time TIMESTAMPTZ NOT NULL,
    -- ... other columns
) PARTITION BY RANGE (start_time);

-- Create partitions for each month
CREATE TABLE shifts_2025_01 PARTITION OF shifts
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE shifts_2025_02 PARTITION OF shifts
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- PostgreSQL automatically routes queries to correct partition
SELECT * FROM shifts WHERE start_time >= '2025-01-15' AND start_time < '2025-01-20';
-- Only scans shifts_2025_01 (not entire table)
```

**Benefits:**
- Query performance stays constant as data grows
- Easy archival (drop old partitions)
- Parallel query execution

**When:** After 6 months (once data volume justifies complexity)

---

#### üîÑ **G. Read Replicas (For High Traffic)**

**Problem:** Dashboard queries compete with roster optimization writes ‚Üí slow for both

**Solution:** Separate read/write databases

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PRIMARY DB     ‚îÇ  ‚Üê All writes (roster generation, employee updates)
‚îÇ  (Write-heavy)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Replication
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  REPLICA DB     ‚îÇ  ‚Üê All reads (dashboard, reports, analytics)
‚îÇ  (Read-only)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Implementation:**

```python
# backend/app/database.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Primary database (reads + writes)
primary_engine = create_engine(os.getenv("DATABASE_URL"))
PrimarySession = sessionmaker(bind=primary_engine)

# Replica database (reads only)
replica_engine = create_engine(os.getenv("DATABASE_REPLICA_URL"))
ReplicaSession = sessionmaker(bind=replica_engine)

# Usage:
def get_db_primary():  # For writes
    db = PrimarySession()
    try:
        yield db
    finally:
        db.close()

def get_db_replica():  # For reads
    db = ReplicaSession()
    try:
        yield db
    finally:
        db.close()

# In routes:
@router.get("/dashboard/metrics")
async def get_metrics(db: Session = Depends(get_db_replica)):  # Use replica
    return compute_metrics(db)

@router.post("/roster/generate")
async def generate_roster(db: Session = Depends(get_db_primary)):  # Use primary
    return create_roster(db)
```

**Expected Impact:**
- Dashboard never slowed by optimization jobs
- 2x database capacity
- Better user experience under load

**Cost:** $50-100/month (managed replica on AWS RDS or DigitalOcean)

**When:** After 200+ active customers (high concurrent load)

---

#### üöÄ **H. Horizontal Scaling (Load Balancing)**

**Problem:** Single server = limited capacity + single point of failure

**Solution:** Multiple app servers behind load balancer

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  LOAD BALANCER   ‚îÇ  (Nginx or AWS ALB)
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                    ‚îÇ                    ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ App 1 ‚îÇ            ‚îÇ App 2 ‚îÇ            ‚îÇ App 3 ‚îÇ  (FastAPI instances)
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                    ‚îÇ                    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   PostgreSQL DB  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Implementation:**

1. **Dockerize Application**

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

2. **Docker Compose for Multiple Instances**

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  nginx:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app1
      - app2

  app1:
    build: ./backend
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis

  app2:
    build: ./backend
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=rostracore
      - POSTGRES_PASSWORD=...

  redis:
    image: redis:7
```

3. **Nginx Load Balancer Config**

```nginx
# nginx.conf
upstream fastapi_backend {
    least_conn;  # Send requests to least-busy server
    server app1:8000;
    server app2:8000;
}

server {
    listen 80;
    server_name rostracore.co.za;

    location / {
        proxy_pass http://fastapi_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

**Expected Impact:**
- Handle 10x more concurrent users
- Zero-downtime deployments (rolling updates)
- Fault tolerance (if one server crashes, others take over)

**When:** After 500+ customers or 50K+ requests/day

---

### Phase 3: Enterprise-Grade (Months 4-12)

#### üîê **I. Advanced Security**

**Current Gaps:**
- No rate limiting (API abuse risk)
- No API key management (for integrations)
- No audit logging (who did what, when?)

**Solutions:**

1. **Rate Limiting** (Prevent abuse)

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.get("/api/v1/roster/generate")
@limiter.limit("10/minute")  # Max 10 roster generations per minute
async def generate_roster(request: Request):
    # ...
```

2. **API Keys** (For integrations)

```python
# New table: api_keys
class APIKey(Base):
    __tablename__ = "api_keys"

    key_id = Column(Integer, primary_key=True)
    org_id = Column(Integer, ForeignKey('organizations.org_id'))
    key_hash = Column(String(255))  # Never store plain key!
    name = Column(String(100))  # "Payroll Integration"
    permissions = Column(JSON)  # ["read:employees", "write:attendance"]
    last_used = Column(DateTime)
    created_at = Column(DateTime)

# Middleware to check API key
@app.middleware("http")
async def validate_api_key(request: Request, call_next):
    if request.url.path.startswith("/api/v1"):
        api_key = request.headers.get("X-API-Key")
        if api_key:
            # Validate and attach to request
            key_record = validate_key(api_key)
            request.state.api_key = key_record

    return await call_next(request)
```

3. **Audit Logging** (Compliance + debugging)

```python
class AuditLog(Base):
    __tablename__ = "audit_logs"

    log_id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey('users.user_id'))
    org_id = Column(Integer, ForeignKey('organizations.org_id'))
    action = Column(String(100))  # "roster.published", "employee.deleted"
    resource_type = Column(String(50))  # "roster", "employee"
    resource_id = Column(Integer)
    details = Column(JSON)  # {"shift_count": 156, "fill_rate": 98}
    ip_address = Column(String(45))
    timestamp = Column(DateTime, default=datetime.utcnow)

# Decorator to auto-log actions
def audit_log(action: str):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            result = await func(*args, **kwargs)

            # Log action
            log_entry = AuditLog(
                user_id=request.state.user.user_id,
                action=action,
                resource_type=extract_resource_type(action),
                details={"result": result}
            )
            db.add(log_entry)
            db.commit()

            return result
        return wrapper
    return decorator

# Usage:
@router.post("/roster/confirm")
@audit_log("roster.published")
async def confirm_roster(roster_id: int):
    # ...
```

---

#### üìä **J. Advanced Analytics Engine**

**Goal:** Move from "descriptive" (what happened?) to "predictive" (what will happen?)

**Components:**

1. **Data Warehouse** (Separate from operational DB)

```
Operational DB (PostgreSQL)  ‚Üí  ETL Pipeline  ‚Üí  Data Warehouse (PostgreSQL or ClickHouse)
     ‚Üë                                                    ‚Üì
  Real-time ops                                    Analytics queries
  (Rosters, Shifts)                                (Trends, Forecasts)
```

2. **ML Model Pipeline**

```python
# Predictive models
from sklearn.ensemble import RandomForestClassifier

class ChurnPredictor:
    """Predict which employees are likely to quit"""

    def train(self, historical_data):
        features = [
            'hours_worked_last_month',
            'hours_worked_trend',  # Increasing or decreasing
            'shifts_rejected_count',
            'avg_distance_to_sites',
            'fairness_score_received',
            'days_since_last_shift',
            'certification_expiring_soon'
        ]

        X = historical_data[features]
        y = historical_data['churned']  # Did employee quit within 30 days?

        self.model = RandomForestClassifier()
        self.model.fit(X, y)

    def predict_churn_risk(self, employee_id):
        features = extract_features(employee_id)
        probability = self.model.predict_proba(features)[0][1]

        return {
            'employee_id': employee_id,
            'churn_risk': probability,
            'risk_level': 'high' if probability > 0.7 else 'medium' if probability > 0.4 else 'low',
            'top_factors': get_feature_importance(features)
        }
```

**Expected Impact:**
- Proactive interventions (retain guards before they quit)
- Competitive differentiation ("Our AI predicts problems")
- Higher customer retention (more value from platform)

---

## PART 3: PERFORMANCE OPTIMIZATION CHECKLIST

### Frontend Optimization

**Current Issues:**
- Bundle size: ~500KB (slow on mobile)
- No code splitting (loads all pages at once)
- Images not optimized (large PNGs)

**Solutions:**

```typescript
// 1. Dynamic imports (code splitting)
// ‚ùå Bad:
import RosterPage from './roster/page'

// ‚úÖ Good:
const RosterPage = dynamic(() => import('./roster/page'), {
  loading: () => <LoadingSpinner />
})


// 2. Image optimization
// ‚ùå Bad:
<img src="/hero-image.png" />  // 2MB PNG

// ‚úÖ Good:
import Image from 'next/image'
<Image
  src="/hero-image.webp"  // 200KB WebP
  width={1200}
  height={600}
  priority  // Preload above-fold images
/>


// 3. Font optimization
// ‚ùå Bad:
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap');

// ‚úÖ Good: Use next/font
import { Inter } from 'next/font/google'
const inter = Inter({ subsets: ['latin'], display: 'swap' })


// 4. Reduce bundle size
// Check what's in bundle:
npm run build
npm run analyze  # (add webpack-bundle-analyzer)

// Common bloat:
// - Moment.js (use date-fns instead)
// - Lodash (import specific functions: import debounce from 'lodash/debounce')
// - Unused Tailwind classes (purge in production)
```

**Expected Results:**
- Bundle size: 500KB ‚Üí 150KB (3.3x smaller)
- First Load: 3s ‚Üí 1.2s (2.5x faster)
- Lighthouse Score: 60 ‚Üí 95+

---

### Backend Optimization

```python
# 1. Database connection pooling
engine = create_engine(
    DATABASE_URL,
    pool_size=20,  # Keep 20 connections ready
    max_overflow=10,  # Allow 10 extra if needed
    pool_pre_ping=True,  # Check connections are alive
    pool_recycle=3600  # Recycle connections every hour
)


# 2. Async database queries (for FastAPI)
from databases import Database

database = Database(DATABASE_URL)

@app.get("/employees")
async def get_employees():
    # ‚úÖ Non-blocking database query
    query = "SELECT * FROM employees WHERE status = 'active'"
    results = await database.fetch_all(query)
    return results


# 3. Response compression
from fastapi.middleware.gzip import GZipMiddleware

app.add_middleware(GZipMiddleware, minimum_size=1000)  # Compress responses > 1KB


# 4. Query result pagination (don't return 10K records)
@app.get("/shifts")
async def get_shifts(page: int = 1, per_page: int = 50):
    offset = (page - 1) * per_page

    shifts = db.query(Shift).offset(offset).limit(per_page).all()
    total = db.query(Shift).count()

    return {
        "data": shifts,
        "pagination": {
            "page": page,
            "per_page": per_page,
            "total": total,
            "pages": math.ceil(total / per_page)
        }
    }
```

---

## PART 4: DEPLOYMENT & DevOps

### Current State: Manual Deployment (Risk)

**Problems:**
- Manual git pull + restart server (error-prone)
- No automated testing before deploy
- No rollback strategy
- Downtime during deployment

### Proposed: CI/CD Pipeline

**Tools:** GitHub Actions (free for public repos, $0.008/minute for private)

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run backend tests
        run: |
          cd backend
          pip install -r requirements.txt
          pytest

      - name: Run frontend tests
        run: |
          cd frontend
          npm install
          npm run test

  deploy:
    needs: test  # Only deploy if tests pass
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to server
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /var/www/rostracore
            git pull origin main
            docker-compose down
            docker-compose up -d --build

      - name: Health check
        run: |
          sleep 10  # Wait for server to start
          curl https://rostracore.co.za/health || exit 1

      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Deployment to production completed!'
```

**Benefits:**
- Automated testing (catch bugs before production)
- Zero-downtime with Docker (start new containers before stopping old)
- Automated rollback if health check fails
- Deployment log (audit trail)

---

## SUMMARY: PHASED IMPLEMENTATION

### üöÄ **Phase 1: Quick Wins (Weeks 1-4) - $7/month**
‚úÖ Redis caching (6-7x faster dashboard)
‚úÖ Sentry monitoring (detect errors instantly)
‚úÖ Celery async jobs (no more timeouts)
‚úÖ Cloudflare CDN (2.5x faster page loads)

**Impact:** Massive UX improvement, minimal cost

---

### üìà **Phase 2: Scaling Foundation (Weeks 5-12) - $150/month**
‚úÖ Database optimization (indexes, query tuning)
‚úÖ Read replicas (2x database capacity)
‚úÖ Load balancing (10x user capacity)
‚úÖ CI/CD pipeline (automated deployments)

**Impact:** Ready for 1,000+ customers

---

### üèÜ **Phase 3: Enterprise-Grade (Months 4-12) - $500/month**
‚úÖ Advanced security (rate limiting, API keys, audit logs)
‚úÖ Predictive analytics (churn, demand forecasting)
‚úÖ Data warehouse (business intelligence)
‚úÖ Multi-region deployment (global reach)

**Impact:** Competitive moat, premium pricing justified

---

**Total Infrastructure Cost Progression:**
- **Today:** ~$50/month (server + database)
- **Phase 1:** ~$57/month (+Redis)
- **Phase 2:** ~$200/month (+replicas +load balancer)
- **Phase 3:** ~$550/month (full enterprise stack)

**Cost per Customer:**
- At 100 customers: $5.50/month per customer
- At 500 customers: $1.10/month per customer
- At 1000 customers: $0.55/month per customer

**Margins:**
- Starter plan (R499 = ~$28 USD): 95% gross margin
- Professional plan (R1,299 = ~$73 USD): 98% gross margin
- Business plan (R2,999 = ~$168 USD): 99% gross margin

**Beautiful SaaS economics.** ‚ú®

---

*Next: Implementation of landing page redesign*
